{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "33861cff-7de2-4a20-9753-c62f159cd8a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skipped 2248.2004-09-23.GP.spam.txt\n",
      "skipped 2526.2004-10-17.GP.spam.txt\n",
      "skipped 2698.2004-10-31.GP.spam.txt\n",
      "skipped 4566.2005-05-24.GP.spam.txt\n",
      "                             name  \\\n",
      "0  0001.1999-12-10.farmer.ham.txt   \n",
      "1  0002.1999-12-13.farmer.ham.txt   \n",
      "2  0003.1999-12-14.farmer.ham.txt   \n",
      "3  0004.1999-12-14.farmer.ham.txt   \n",
      "4  0005.1999-12-14.farmer.ham.txt   \n",
      "\n",
      "                                             content category  \n",
      "0            Subject: christmas tree farm pictures\\n      ham  \n",
      "1  Subject: vastar resources , inc .\\ngary , prod...      ham  \n",
      "2  Subject: calpine daily gas nomination\\n- calpi...      ham  \n",
      "3  Subject: re : issue\\nfyi - see note below - al...      ham  \n",
      "4  Subject: meter 7268 nov allocation\\nfyi .\\n- -...      ham  \n",
      "Accuracy: 0.9748549323017408\n",
      "Confusion Matrix:\n",
      " [[717  12]\n",
      " [ 14 291]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.98      0.98      0.98       729\n",
      "        spam       0.96      0.95      0.96       305\n",
      "\n",
      "    accuracy                           0.97      1034\n",
      "   macro avg       0.97      0.97      0.97      1034\n",
      "weighted avg       0.97      0.97      0.97      1034\n",
      "\n",
      "Top 10 Positive Features (Spam):\n",
      "no 0.9200891034671764\n",
      "http 0.853581450861418\n",
      "prices 0.851243327236229\n",
      "remove 0.7604387976104392\n",
      "hello 0.736282876581915\n",
      "only 0.7112630004191409\n",
      "removed 0.6774089145037472\n",
      "here 0.6636794753467545\n",
      "more 0.625946422313018\n",
      "paliourg 0.6223165120440506\n",
      "\n",
      "Top 10 Negative Features (Ham):\n",
      "enron -1.493969657939129\n",
      "thanks -1.4594084652321757\n",
      "attached -1.3685362731392547\n",
      "doc -1.3259743104924486\n",
      "daren -1.2954903084981428\n",
      "pictures -1.2922090371528203\n",
      "xls -1.2270583532740567\n",
      "deal -1.154972123566215\n",
      "neon -1.152822357208288\n",
      "hpl -1.0434609874893177\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "\n",
    "def read_spam():\n",
    "    category = 'spam'\n",
    "    directory = './enron1/spam'\n",
    "    return read_category(category, directory)\n",
    "\n",
    "def read_ham():\n",
    "    category = 'ham'\n",
    "    directory = './enron1/ham'\n",
    "    return read_category(category, directory)\n",
    "\n",
    "def read_category(category, directory):\n",
    "    emails = []\n",
    "    for filename in os.listdir(directory):\n",
    "        if not filename.endswith(\".txt\"):\n",
    "            continue\n",
    "        with open(os.path.join(directory, filename), 'r') as fp:\n",
    "            try:\n",
    "                content = fp.read()\n",
    "                emails.append({'name': filename, 'content': content, 'category': category})\n",
    "            except:\n",
    "                print(f'skipped {filename}')\n",
    "    return emails\n",
    "    \n",
    "def preprocessor(e):\n",
    "    # Replace all non-alphabet characters with a space\n",
    "    e = re.sub('[^a-zA-Z]', ' ', e)\n",
    "    # Convert the string to lowercase\n",
    "    return e.lower()\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# The CountVectorizer converts a text sample into a vector (think of it as an array of floats).\n",
    "vectorizer = CountVectorizer(preprocessor=preprocessor)\n",
    "\n",
    "# Use train_test_split to split the dataset into a train dataset and a test dataset.\n",
    "X = df['content']\n",
    "y = df['category']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Use the vectorizer to transform the existing dataset into a form in which the model can learn from.\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "# Use the LogisticRegression model to fit to the train dataset.\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_vec, y_train)\n",
    "\n",
    "# Then generate the predictions.\n",
    "y_pred = model.predict(X_test_vec)\n",
    "\n",
    "#create the vectorizer\n",
    "features = vectorizer.get_feature_names_out()\n",
    "\n",
    "\n",
    "# You can access these numbers known as \"coefficients\" from the coef_ property of the model\n",
    "# We will be looking at coef_[0] which represents the importance of each feature.\n",
    "importance = model.coef_[0]\n",
    "\n",
    "#Get top 10 positive and negative features\n",
    "top_positive_features = sorted(zip(importance, features), reverse=True)[:10]\n",
    "top_negative_features = sorted(zip(importance, features))[:10]\n",
    "\n",
    "\n",
    "ham = read_ham()\n",
    "spam = read_spam()\n",
    "\n",
    "df_ham = pd.DataFrame.from_records(ham)\n",
    "df_spam = pd.DataFrame.from_records(spam)\n",
    "\n",
    "df = pd.concat([df_ham, df_spam], ignore_index=True)\n",
    "\n",
    "\n",
    "print(df.head())\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"Top 10 Positive Features (Spam):\")\n",
    "for coef, feature in top_positive_features:\n",
    "    print(feature, coef)\n",
    "\n",
    "print(\"\\nTop 10 Negative Features (Ham):\")\n",
    "for coef, feature in top_negative_features:\n",
    "    print(feature, coef)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe3ac6c-ce2d-4e69-9aa5-5e37de3eb1f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
